{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsa87/semi-jtvae/blob/master/semi_jtvae_train_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guV5MREtUXjp",
        "outputId": "8b3f5c82-d7ba-4329-b059-a2666ee1c615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 25 02:59:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shGMcYBm3Nic",
        "outputId": "1f8b0cb9-9e09-4486-dcf4-7231829c37ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JDinHdioUZRH",
        "outputId": "1a824742-d528-46a2-8d89-7697a166c20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Collecting torch==1.10.1+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.1%2Bcu113-cp37-cp37m-linux_x86_64.whl (1821.5 MB)\n",
            "\u001b[K     |██████████████▋                 | 834.1 MB 1.2 MB/s eta 0:13:48tcmalloc: large alloc 1147494400 bytes == 0x564dde98e000 @  0x7fc7e0a2e615 0x564ddbde817c 0x564ddbec847a 0x564ddbdeaf9d 0x564ddbedcd4d 0x564ddbe5eec8 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ed30 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbdecce9 0x564ddbe30579 0x564ddbdeb902 0x564ddbe5ec4d 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5a8f6 0x564ddbdec7aa 0x564ddbe5ab4f 0x564ddbe59a2e\n",
            "\u001b[K     |██████████████████▌             | 1055.7 MB 1.2 MB/s eta 0:10:25tcmalloc: large alloc 1434370048 bytes == 0x564e22fe4000 @  0x7fc7e0a2e615 0x564ddbde817c 0x564ddbec847a 0x564ddbdeaf9d 0x564ddbedcd4d 0x564ddbe5eec8 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ed30 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbdecce9 0x564ddbe30579 0x564ddbdeb902 0x564ddbe5ec4d 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5a8f6 0x564ddbdec7aa 0x564ddbe5ab4f 0x564ddbe59a2e\n",
            "\u001b[K     |███████████████████████▌        | 1336.2 MB 1.2 MB/s eta 0:06:45tcmalloc: large alloc 1792966656 bytes == 0x564e787d0000 @  0x7fc7e0a2e615 0x564ddbde817c 0x564ddbec847a 0x564ddbdeaf9d 0x564ddbedcd4d 0x564ddbe5eec8 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ed30 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbdecce9 0x564ddbe30579 0x564ddbdeb902 0x564ddbe5ec4d 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5a8f6 0x564ddbdec7aa 0x564ddbe5ab4f 0x564ddbe59a2e\n",
            "\u001b[K     |█████████████████████████████▊  | 1691.1 MB 1.1 MB/s eta 0:01:56tcmalloc: large alloc 2241208320 bytes == 0x564dde98e000 @  0x7fc7e0a2e615 0x564ddbde817c 0x564ddbec847a 0x564ddbdeaf9d 0x564ddbedcd4d 0x564ddbe5eec8 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ed30 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbeddb76 0x564ddbe5ad95 0x564ddbdecce9 0x564ddbe30579 0x564ddbdeb902 0x564ddbe5ec4d 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5a8f6 0x564ddbdec7aa 0x564ddbe5ab4f 0x564ddbe59a2e\n",
            "\u001b[K     |████████████████████████████████| 1821.5 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 1821458432 bytes == 0x564e642f0000 @  0x7fc7e0a2d1e7 0x564ddbe1e407 0x564ddbde817c 0x564ddbec847a 0x564ddbdeaf9d 0x564ddbedcd4d 0x564ddbe5eec8 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbdec7aa 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e\n",
            "tcmalloc: large alloc 2276827136 bytes == 0x564ed0c04000 @  0x7fc7e0a2e615 0x564ddbde817c 0x564ddbec847a 0x564ddbdeaf9d 0x564ddbedcd4d 0x564ddbe5eec8 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5ab4f 0x564ddbdec7aa 0x564ddbe5ab4f 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e 0x564ddbdec88a 0x564ddbe5b719 0x564ddbe59a2e 0x564ddbdecf21\n",
            "\u001b[K     |████████████████████████████████| 1821.5 MB 6.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.1+cu113) (3.10.0.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.10.1+cu113 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.1+cu113 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.10.1+cu113 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.1+cu113\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.1 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 43.9 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 67.3 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 74.3 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=139e482c3012140161b0d0d7c62a56e5be0282eb325b96d177f43fe6f175259c\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0 torch-geometric-2.0.4 torch-scatter-2.0.9 torch-sparse-0.6.13 torch-spline-conv-1.2.1\n",
            "Collecting dive-into-graphs\n",
            "  Downloading dive_into_graphs-0.1.2-py3-none-any.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 15.9 MB/s \n",
            "\u001b[?25hCollecting typed-argument-parser==1.5.4\n",
            "  Downloading typed-argument-parser-1.5.4.tar.gz (22 kB)\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.9.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting shap\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 88.8 MB/s \n",
            "\u001b[?25hCollecting captum==0.2.0\n",
            "  Downloading captum-0.2.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 74.5 MB/s \n",
            "\u001b[?25hCollecting cilog\n",
            "  Downloading cilog-1.2.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from dive-into-graphs) (1.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from dive-into-graphs) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from dive-into-graphs) (1.4.1)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 89.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dive-into-graphs) (4.63.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from dive-into-graphs) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum==0.2.0->dive-into-graphs) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum==0.2.0->dive-into-graphs) (1.10.1+cu113)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum==0.2.0->dive-into-graphs) (3.2.2)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from typed-argument-parser==1.5.4->dive-into-graphs) (3.10.0.2)\n",
            "Collecting typing-inspect>=0.5\n",
            "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (from cilog->dive-into-graphs) (3.0.9)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from cilog->dive-into-graphs) (0.8.9)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 90.5 MB/s \n",
            "\u001b[?25hCollecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->dive-into-graphs) (5.4.0)\n",
            "Collecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 90.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->dive-into-graphs) (3.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->dive-into-graphs) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->dive-into-graphs) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->dive-into-graphs) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0->dive-into-graphs) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0->dive-into-graphs) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0->dive-into-graphs) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0->dive-into-graphs) (0.11.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl->cilog->dive-into-graphs) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->dive-into-graphs) (2018.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->dive-into-graphs) (0.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi->dive-into-graphs) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap->dive-into-graphs) (1.0.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->dive-into-graphs) (1.3.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap->dive-into-graphs) (21.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->dive-into-graphs) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->dive-into-graphs) (0.34.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap->dive-into-graphs) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap->dive-into-graphs) (3.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->dive-into-graphs) (1.2.1)\n",
            "Building wheels for collected packages: typed-argument-parser, antlr4-python3-runtime\n",
            "  Building wheel for typed-argument-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typed-argument-parser: filename=typed_argument_parser-1.5.4-py3-none-any.whl size=18301 sha256=3ea282775afab65467f18a0d2d9b4c7d32b9b11096caf231771b7b805e40299a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/f8/d2/1850774c1ea9859022eb6ca41fc6d428577abadec0dc3ed99b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=870dc4d01042e55e0f9884ba49573af7fba050739026bc9327e67033864f30ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built typed-argument-parser antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, mypy-extensions, antlr4-python3-runtime, typing-inspect, slicer, omegaconf, typed-argument-parser, shap, rdkit-pypi, hydra-core, cilog, captum, dive-into-graphs\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 captum-0.2.0 cilog-1.2.2 dive-into-graphs-0.1.2 hydra-core-1.1.1 mypy-extensions-0.4.3 omegaconf-2.1.1 rdkit-pypi-2021.9.5.1 shap-0.40.0 slicer-0.0.7 typed-argument-parser-1.5.4 typing-inspect-0.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch==1.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install dive-into-graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XryC9VxeWsP3",
        "outputId": "136de950-9706-45fb-cded-bc6a671a6892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anb-net'...\n",
            "remote: Enumerating objects: 278, done.\u001b[K\n",
            "remote: Counting objects: 100% (278/278), done.\u001b[K\n",
            "remote: Compressing objects: 100% (195/195), done.\u001b[K\n",
            "remote: Total 278 (delta 76), reused 254 (delta 58), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (278/278), 8.73 MiB | 25.69 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "/content/anb-net\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tsa87/anb-net\n",
        "%cd anb-net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RKgd8MsYOYh"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os\n",
        "import json\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from dig.ggraph.dataset import ZINC250k, ZINC800\n",
        "from molecule_optimizer.externals.fast_jtnn.datautils import SemiMolTreeFolder\n",
        "from molecule_optimizer.runner.semi_jtvae import SemiJTVAEGeneratorPredictor\n",
        "from torch_geometric.data import DenseDataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C4erValhPS-"
      },
      "outputs": [],
      "source": [
        "conf = json.load(open(\"training/configs/rand_gen_zinc250k_config_dict.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuzGX7ClhKaf",
        "outputId": "ab764f6b-4dd7-4ffc-b6cf-bae47d6cedf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Dataset...\n",
            "making raw files: ../data/zinc/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/divelab/DIG_storage/main/ggraph/zinc250k_property.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing...\n",
            "making processed files: ../data/zinc/zinc250k_property/processed\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"Processing Dataset...\")\n",
        "_ = ZINC250k(\n",
        "    root=conf[\"data\"][\"root\"],\n",
        "    one_shot=False,\n",
        "    use_aug=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeUcmLrzUrLy"
      },
      "outputs": [],
      "source": [
        "zinc_250_jt = torch.load(\n",
        "    os.path.join(conf[\"data\"][\"root\"], conf[\"data\"][\"processed_path\"])\n",
        ")\n",
        "smiles = zinc_250_jt[-1]\n",
        "labels = zinc_250_jt[0].y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UJa-qP7UrLy"
      },
      "outputs": [],
      "source": [
        "runner = SemiJTVAEGeneratorPredictor(smiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-1xXVU15z6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c328fe-72e4-4401-bce6-8613e7e9319f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ],
      "source": [
        "runner.get_model(\n",
        "    \"rand_gen\",\n",
        "    {\n",
        "        \"hidden_size\": conf[\"model\"][\"hidden_size\"],\n",
        "        \"latent_size\": conf[\"model\"][\"latent_size\"],\n",
        "        \"depthT\": conf[\"model\"][\"depthT\"],\n",
        "        \"depthG\": conf[\"model\"][\"depthG\"],\n",
        "        \"label_size\": 1,\n",
        "        \"label_mean\": float(torch.mean(labels)),\n",
        "        \"label_var\": float(torch.var(labels)),\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(runner))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0g4QthH_67-",
        "outputId": "ffa74576-43b7-41ac-e62c-8acd24e1f5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'molecule_optimizer.runner.semi_jtvae.SemiJTVAEGeneratorPredictor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "filehandler = open('runner.xml', 'wb') \n",
        "pickle.dump(runner, filehandler)"
      ],
      "metadata": {
        "id": "1ihEEA3FvgrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filehandler = open('runner.xml', 'rb') \n",
        "runner = pickle.load(filehandler)"
      ],
      "metadata": {
        "id": "uTNMpfWD7b7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGnpfkM_KQXi"
      },
      "outputs": [],
      "source": [
        "preprocessed, labels = runner.preprocess(smiles, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k19uZMZN9H05"
      },
      "outputs": [],
      "source": [
        "loader = SemiMolTreeFolder(\n",
        "      preprocessed,\n",
        "      labels,\n",
        "      runner.vocab,\n",
        "      conf[\"batch_size\"],\n",
        "      num_workers=conf[\"num_workers\"],\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMxgCK1Y20mu"
      },
      "outputs": [],
      "source": [
        "print(\"Training model...\")\n",
        "runner.train_gen_pred(\n",
        "    loader=loader,\n",
        "    load_epoch=0,\n",
        "    lr=conf[\"lr\"],\n",
        "    anneal_rate=conf[\"anneal_rate\"],\n",
        "    clip_norm=conf[\"clip_norm\"],\n",
        "    num_epochs=conf[\"num_epochs\"],\n",
        "    alpha=conf[\"alpha\"],\n",
        "    beta=conf[\"beta\"],\n",
        "    max_beta=conf[\"max_beta\"],\n",
        "    step_beta=conf[\"step_beta\"],\n",
        "    anneal_iter=conf[\"anneal_iter\"],\n",
        "    kl_anneal_iter=conf[\"kl_anneal_iter\"],\n",
        "    print_iter=conf[\"print_iter\"],\n",
        "    save_iter=conf[\"save_iter\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xuRfCE039_5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of google_colab.ipynb",
      "provenance": [],
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}