{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr:0.001\n",
    "# anneal_rate:0.9\n",
    "# batch_size:32\n",
    "# clip_norm:50\n",
    "# num_epochs:5\n",
    "# alpha:250\n",
    "# beta:0\n",
    "# max_beta:1\n",
    "# step_beta:0.002\n",
    "# anneal_iter:40000\n",
    "# kl_anneal_iter:2000\n",
    "# print_iter:100\n",
    "# save_iter:5000\n",
    "# num_workers:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "gradient": {
     "editing": false,
     "id": "18de9aeb-6551-42f6-8c11-a0e30bd207d6",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "JDinHdioUZRH",
    "outputId": "1a824742-d528-46a2-8d89-7697a166c20f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
    "!pip install -q dive-into-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q toolz\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f728113a-ff43-466d-b34d-77c9b2e11478",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "_RKgd8MsYOYh"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from molecule_optimizer.externals.fast_jtnn.datautils import SemiMolTreeFolder, SemiMolTreeFolderTest\n",
    "from molecule_optimizer.runner.semi_jtvae import SemiJTVAEGeneratorPredictor\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "\n",
    "import rdkit\n",
    "\n",
    "lg = rdkit.RDLogger.logger() \n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6e85f4e2-eab6-4eae-b452-7f089e176039",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "2C4erValhPS-"
   },
   "outputs": [],
   "source": [
    "conf = json.load(open(\"training/configs/rand_gen_zinc250k_config_dict.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": true,
     "id": "30eb7f71-c38e-49f6-8d84-715ff3d80e08",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "SuzGX7ClhKaf",
    "outputId": "ab764f6b-4dd7-4ffc-b6cf-bae47d6cedf7"
   },
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"ZINC_310k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = csv['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = smiles[:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(csv['QED'][:60000]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'runner.xml' not in os.listdir(\".\"):\n",
    "#     runner = SemiJTVAEGeneratorPredictor(smiles)\n",
    "#     with open('runner.xml', 'wb') as f:\n",
    "#         pickle.dump(runner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'runner_20.xml' not in os.listdir(\".\"):\n",
    "    runner = SemiJTVAEGeneratorPredictor(smiles)\n",
    "    with open('runner_20.xml', 'wb') as f:\n",
    "        pickle.dump(runner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fc02ae3d-696b-4c2e-b557-760e6a1a75a9",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "uTNMpfWD7b7Q"
   },
   "outputs": [],
   "source": [
    "# with open('runner.xml', 'rb') as f:\n",
    "#     runner = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fc02ae3d-696b-4c2e-b557-760e6a1a75a9",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "uTNMpfWD7b7Q"
   },
   "outputs": [],
   "source": [
    "with open('runner_20.xml', 'rb') as f:\n",
    "    runner = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "4ccc9136-0e87-470b-90eb-8e0b92da52bc",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "0-1xXVU15z6N",
    "outputId": "c6c328fe-72e4-4401-bce6-8613e7e9319f"
   },
   "outputs": [],
   "source": [
    "runner.get_model(\n",
    "    \"rand_gen\",\n",
    "    {\n",
    "        \"hidden_size\": conf[\"model\"][\"hidden_size\"],\n",
    "        \"latent_size\": conf[\"model\"][\"latent_size\"],\n",
    "        \"depthT\": conf[\"model\"][\"depthT\"],\n",
    "        \"depthG\": conf[\"model\"][\"depthG\"],\n",
    "        \"label_size\": 1,\n",
    "        \"label_mean\": float(torch.mean(labels)),\n",
    "        \"label_var\": float(torch.var(labels)),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c177219a-298a-4994-98b9-de76833e14fe",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "IGnpfkM_KQXi"
   },
   "outputs": [],
   "source": [
    "labels = runner.get_processed_labels(labels)\n",
    "preprocessed = runner.processed_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_TEST = 10000\n",
    "N_TEST = 200\n",
    "VAL_FRAC = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_id=np.random.permutation(len(labels))\n",
    "X_train = preprocessed[perm_id[N_TEST:]]\n",
    "L_train = torch.tensor(labels.numpy()[perm_id[N_TEST:]])\n",
    "\n",
    "\n",
    "X_test = preprocessed[perm_id[:N_TEST]]\n",
    "L_test = torch.tensor(labels.numpy()[perm_id[:N_TEST]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cut = math.floor(len(X_train) * VAL_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Val = X_train[:val_cut]\n",
    "L_Val = L_train[:val_cut]\n",
    "\n",
    "X_train = X_train[val_cut :]\n",
    "L_train = L_train[val_cut :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Val = X_train[:val_cut]\n",
    "L_Val = L_train[:val_cut]\n",
    "\n",
    "X_train = X_train[val_cut :]\n",
    "L_train = L_train[val_cut :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = SemiMolTreeFolder(\n",
    "    X_train,\n",
    "    L_train,\n",
    "    runner.vocab,\n",
    "    conf[\"batch_size\"],\n",
    "    label_pct=0.05,\n",
    "    num_workers=conf[\"num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "25d5a0be-b1f8-454e-bc3a-82d8489ac3ca",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "k19uZMZN9H05"
   },
   "outputs": [],
   "source": [
    "test_loader = SemiMolTreeFolderTest(\n",
    "    X_test,\n",
    "    L_test,\n",
    "    runner.vocab,\n",
    "    conf[\"batch_size\"],\n",
    "    num_workers=conf[\"num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = math.floor(len(X_Val) / 10)\n",
    "\n",
    "val_loader = SemiMolTreeFolderTest(\n",
    "    X_Val,\n",
    "    L_Val,\n",
    "    runner.vocab,\n",
    "    batch_size_val,\n",
    "    num_workers=conf[\"num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7cb9e705-09fa-4075-a487-21887ecaeb95",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "TMxgCK1Y20mu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Model #Params: 4732K\n",
      "[Train][100] Alpha: 25.855, Beta: 0.000, Loss: 185.83, KL: 88.31, MAE: 0.11605, Word Loss: 93.89, Topo Loss: 25.57, Assm Loss: 8.96, Pred Loss: 0.86, Word: 26.94, Topo: 79.60, Assm: 54.69, PNorm: 101.80, GNorm: 50.00\n",
      "[Train][200] Alpha: 97.049, Beta: 0.000, Loss: 112.03, KL: 114.33, MAE: 0.09732, Word Loss: 59.12, Topo Loss: 14.13, Assm Loss: 8.29, Pred Loss: 0.61, Word: 47.17, Topo: 90.21, Assm: 59.58, PNorm: 106.20, GNorm: 50.00\n",
      "[Train][300] Alpha: 45.178, Beta: 0.000, Loss: 100.00, KL: 166.14, MAE: 0.08528, Word Loss: 51.28, Topo Loss: 12.61, Assm Loss: 8.26, Pred Loss: 0.47, Word: 54.77, Topo: 91.20, Assm: 59.23, PNorm: 109.49, GNorm: 50.00\n",
      "[Train][400] Alpha: 65.815, Beta: 0.000, Loss: 90.68, KL: 198.94, MAE: 0.08198, Word Loss: 47.03, Topo Loss: 10.52, Assm Loss: 7.81, Pred Loss: 0.42, Word: 58.13, Topo: 92.60, Assm: 61.20, PNorm: 112.49, GNorm: 50.00\n",
      "[Train][500] Alpha: 38.085, Beta: 0.000, Loss: 88.47, KL: 235.73, MAE: 0.07544, Word Loss: 44.59, Topo Loss: 9.83, Assm Loss: 7.87, Pred Loss: 0.38, Word: 60.25, Topo: 93.06, Assm: 62.44, PNorm: 115.55, GNorm: 50.00\n",
      "[Train][600] Alpha: 101.568, Beta: 0.000, Loss: 82.13, KL: 243.53, MAE: 0.07249, Word Loss: 42.41, Topo Loss: 9.32, Assm Loss: 7.59, Pred Loss: 0.35, Word: 61.94, Topo: 93.47, Assm: 62.27, PNorm: 117.86, GNorm: 50.00\n",
      "[Train][700] Alpha: 84.118, Beta: 0.000, Loss: 78.61, KL: 273.34, MAE: 0.07123, Word Loss: 40.23, Topo Loss: 8.60, Assm Loss: 7.43, Pred Loss: 0.33, Word: 63.98, Topo: 93.94, Assm: 63.72, PNorm: 120.69, GNorm: 50.00\n",
      "[Train][800] Alpha: 55.483, Beta: 0.000, Loss: 75.45, KL: 307.54, MAE: 0.06649, Word Loss: 38.36, Topo Loss: 8.24, Assm Loss: 7.44, Pred Loss: 0.30, Word: 65.30, Topo: 94.23, Assm: 64.35, PNorm: 123.28, GNorm: 50.00\n",
      "[Train][900] Alpha: 79.218, Beta: 0.000, Loss: 73.93, KL: 317.04, MAE: 0.06476, Word Loss: 37.74, Topo Loss: 7.81, Assm Loss: 7.18, Pred Loss: 0.28, Word: 65.62, Topo: 94.49, Assm: 64.72, PNorm: 125.40, GNorm: 50.00\n",
      "[Train][1000] Alpha: 55.701, Beta: 0.000, Loss: 69.31, KL: 328.62, MAE: 0.06506, Word Loss: 35.56, Topo Loss: 7.48, Assm Loss: 6.92, Pred Loss: 0.28, Word: 67.42, Topo: 94.72, Assm: 66.32, PNorm: 128.00, GNorm: 50.00\n",
      "[Train][1100] Alpha: 114.236, Beta: 0.000, Loss: 69.35, KL: 338.25, MAE: 0.06008, Word Loss: 35.05, Topo Loss: 7.52, Assm Loss: 7.06, Pred Loss: 0.25, Word: 67.43, Topo: 94.58, Assm: 65.91, PNorm: 130.64, GNorm: 50.00\n",
      "[Train][1200] Alpha: 38.984, Beta: 0.000, Loss: 67.35, KL: 349.64, MAE: 0.06196, Word Loss: 33.89, Topo Loss: 7.20, Assm Loss: 6.95, Pred Loss: 0.26, Word: 68.53, Topo: 94.85, Assm: 65.80, PNorm: 133.09, GNorm: 50.00\n",
      "[Train][1300] Alpha: 123.353, Beta: 0.000, Loss: 64.59, KL: 366.57, MAE: 0.05864, Word Loss: 32.56, Topo Loss: 6.65, Assm Loss: 6.65, Pred Loss: 0.23, Word: 69.38, Topo: 95.36, Assm: 68.31, PNorm: 135.70, GNorm: 50.00\n",
      "[Train][1400] Alpha: 94.505, Beta: 0.000, Loss: 62.97, KL: 379.47, MAE: 0.05482, Word Loss: 31.49, Topo Loss: 7.17, Assm Loss: 6.74, Pred Loss: 0.20, Word: 70.20, Topo: 94.90, Assm: 67.69, PNorm: 138.27, GNorm: 50.00\n",
      "[Train][1500] Alpha: 76.964, Beta: 0.000, Loss: 61.27, KL: 399.17, MAE: 0.05539, Word Loss: 30.41, Topo Loss: 6.42, Assm Loss: 6.43, Pred Loss: 0.20, Word: 71.02, Topo: 95.61, Assm: 68.49, PNorm: 140.73, GNorm: 50.00\n",
      "[Train][1600] Alpha: 64.410, Beta: 0.000, Loss: 59.49, KL: 415.60, MAE: 0.05359, Word Loss: 29.17, Topo Loss: 6.07, Assm Loss: 6.37, Pred Loss: 0.19, Word: 72.04, Topo: 95.72, Assm: 70.26, PNorm: 143.00, GNorm: 50.00\n",
      "[Train][1700] Alpha: 66.594, Beta: 0.000, Loss: 57.84, KL: 418.15, MAE: 0.05096, Word Loss: 28.23, Topo Loss: 6.33, Assm Loss: 6.17, Pred Loss: 0.17, Word: 72.71, Topo: 95.54, Assm: 69.86, PNorm: 145.25, GNorm: 50.00\n",
      "[Train][1800] Alpha: 68.139, Beta: 0.000, Loss: 52.79, KL: 442.80, MAE: 0.05090, Word Loss: 26.19, Topo Loss: 5.58, Assm Loss: 5.89, Pred Loss: 0.17, Word: 74.32, Topo: 96.11, Assm: 71.91, PNorm: 147.68, GNorm: 50.00\n",
      "[Train][1900] Alpha: 116.636, Beta: 0.000, Loss: 52.13, KL: 439.02, MAE: 0.05368, Word Loss: 25.58, Topo Loss: 5.37, Assm Loss: 6.04, Pred Loss: 0.19, Word: 74.83, Topo: 96.29, Assm: 71.42, PNorm: 149.81, GNorm: 50.00\n",
      "[Train][2000] Alpha: 77.413, Beta: 0.000, Loss: 50.42, KL: 461.41, MAE: 0.04731, Word Loss: 24.85, Topo Loss: 5.34, Assm Loss: 5.93, Pred Loss: 0.15, Word: 75.35, Topo: 96.22, Assm: 71.40, PNorm: 152.05, GNorm: 50.00\n",
      "[Train][2100] Alpha: 69.863, Beta: 0.000, Loss: 45.54, KL: 483.17, MAE: 0.04729, Word Loss: 22.76, Topo Loss: 4.63, Assm Loss: 5.60, Pred Loss: 0.15, Word: 77.24, Topo: 96.84, Assm: 73.62, PNorm: 154.52, GNorm: 50.00\n",
      "[Train][2200] Alpha: 57.997, Beta: 0.000, Loss: 47.44, KL: 483.61, MAE: 0.04906, Word Loss: 23.08, Topo Loss: 5.29, Assm Loss: 5.57, Pred Loss: 0.16, Word: 76.78, Topo: 96.34, Assm: 73.71, PNorm: 156.65, GNorm: 50.00\n",
      "[Train][2300] Alpha: 72.624, Beta: 0.000, Loss: 43.00, KL: 496.75, MAE: 0.04346, Word Loss: 21.02, Topo Loss: 4.60, Assm Loss: 5.35, Pred Loss: 0.12, Word: 78.50, Topo: 96.86, Assm: 74.50, PNorm: 158.97, GNorm: 50.00\n",
      "[Train][2400] Alpha: 166.439, Beta: 0.000, Loss: 41.47, KL: 515.99, MAE: 0.04495, Word Loss: 19.75, Topo Loss: 4.43, Assm Loss: 5.13, Pred Loss: 0.14, Word: 80.01, Topo: 96.92, Assm: 76.29, PNorm: 161.34, GNorm: 50.00\n",
      "[Train][2500] Alpha: 147.792, Beta: 0.000, Loss: 39.97, KL: 526.57, MAE: 0.04071, Word Loss: 18.98, Topo Loss: 4.54, Assm Loss: 4.87, Pred Loss: 0.11, Word: 80.60, Topo: 96.91, Assm: 77.33, PNorm: 163.59, GNorm: 50.00\n",
      "[Train][2600] Alpha: 163.826, Beta: 0.000, Loss: 38.33, KL: 557.13, MAE: 0.04237, Word Loss: 18.30, Topo Loss: 4.68, Assm Loss: 4.56, Pred Loss: 0.12, Word: 81.15, Topo: 96.77, Assm: 79.41, PNorm: 165.90, GNorm: 50.00\n",
      "[Train][2700] Alpha: 166.342, Beta: 0.000, Loss: 34.76, KL: 570.35, MAE: 0.04213, Word Loss: 16.45, Topo Loss: 3.80, Assm Loss: 4.45, Pred Loss: 0.12, Word: 83.19, Topo: 97.41, Assm: 80.15, PNorm: 168.15, GNorm: 50.00\n",
      "[Train][2800] Alpha: 45.103, Beta: 0.000, Loss: 33.63, KL: 569.91, MAE: 0.04046, Word Loss: 16.18, Topo Loss: 3.29, Assm Loss: 4.38, Pred Loss: 0.11, Word: 83.21, Topo: 97.86, Assm: 80.24, PNorm: 169.89, GNorm: 50.00\n",
      "[Train][2900] Alpha: 152.953, Beta: 0.000, Loss: 33.10, KL: 586.93, MAE: 0.04586, Word Loss: 15.10, Topo Loss: 4.06, Assm Loss: 4.06, Pred Loss: 0.14, Word: 84.11, Topo: 97.35, Assm: 81.39, PNorm: 171.95, GNorm: 50.00\n",
      "[Train][3000] Alpha: 43.459, Beta: 0.000, Loss: 30.45, KL: 588.68, MAE: 0.04176, Word Loss: 14.49, Topo Loss: 3.33, Assm Loss: 3.73, Pred Loss: 0.12, Word: 84.56, Topo: 97.81, Assm: 83.05, PNorm: 173.91, GNorm: 50.00\n",
      "[Validation][10] Alpha: 258.002, Beta: 0.000, Loss: 104.81, KL: 290.66, MAE: 0.06391, Word Loss: 21.44, Topo Loss: 6.26, Assm Loss: 4.18, Pred Loss: 0.28, Word: 68.96, Topo: 93.91, Assm: 70.38\n",
      "[Test][12] Alpha: 258.002, Beta: 0.000, Loss: 99.44, KL: 298.30, MAE: 0.06244, Word Loss: 20.26, Topo Loss: 5.65, Assm Loss: 4.13, Pred Loss: 0.27, Word: 70.26, Topo: 94.07, Assm: 71.71\n",
      "[Train][3100] Alpha: 136.069, Beta: 0.000, Loss: 31045.07, KL: 27628.18, MAE: 0.15269, Word Loss: 17.23, Topo Loss: 7.89, Assm Loss: 174.82, Pred Loss: 292.41, Word: 86.15, Topo: 97.79, Assm: 81.13, PNorm: 176.25, GNorm: 50.00\n",
      "[Train][3200] Alpha: 88.870, Beta: 0.000, Loss: 63993939.64, KL: 38592261.22, MAE: 3.05502, Word Loss: 15.06, Topo Loss: 53.56, Assm Loss: 365727.49, Pred Loss: 519948.13, Word: 86.83, Topo: 97.72, Assm: 81.17, PNorm: 178.42, GNorm: 50.00\n",
      "[Train][3300] Alpha: 54.727, Beta: 0.000, Loss: 2367410.55, KL: 15252091.19, MAE: 0.68958, Word Loss: 121.46, Topo Loss: 44.37, Assm Loss: 22709.99, Pred Loss: 18073.42, Word: 88.22, Topo: 97.90, Assm: 84.04, PNorm: 180.27, GNorm: 50.00\n",
      "[Train][3400] Alpha: 155.757, Beta: 0.000, Loss: 5294.31, KL: 20106.39, MAE: 0.07466, Word Loss: 16.35, Topo Loss: 4.00, Assm Loss: 13.07, Pred Loss: 85.77, Word: 89.12, Topo: 98.24, Assm: 84.29, PNorm: 182.18, GNorm: 50.00\n",
      "[Train][3500] Alpha: 128.410, Beta: 0.000, Loss: 11173045.11, KL: 5940840.88, MAE: 1.69215, Word Loss: 173.23, Topo Loss: 31.00, Assm Loss: 53514.25, Pred Loss: 160506.86, Word: 89.84, Topo: 98.19, Assm: 84.64, PNorm: 183.87, GNorm: 50.00\n",
      "[Train][3600] Alpha: 119.172, Beta: 0.000, Loss: 12943.97, KL: 27272.58, MAE: 0.10471, Word Loss: 17.77, Topo Loss: 4.21, Assm Loss: 32.63, Pred Loss: 127.46, Word: 90.63, Topo: 98.38, Assm: 86.43, PNorm: 185.55, GNorm: 50.00\n",
      "[Train][3700] Alpha: 69.713, Beta: 0.000, Loss: 3636219.28, KL: 7331655.59, MAE: 0.98566, Word Loss: 145.46, Topo Loss: 33.71, Assm Loss: 14165.79, Pred Loss: 40113.93, Word: 90.78, Topo: 98.43, Assm: 86.16, PNorm: 187.00, GNorm: 50.00\n",
      "[Train][3800] Alpha: 113.051, Beta: 0.000, Loss: 530.28, KL: 28503.26, MAE: 0.03739, Word Loss: 12.65, Topo Loss: 2.82, Assm Loss: 176.25, Pred Loss: 5.21, Word: 92.56, Topo: 98.74, Assm: 88.14, PNorm: 188.46, GNorm: 50.00\n",
      "[Train][3900] Alpha: 69.545, Beta: 0.000, Loss: 5206.93, KL: 332636.34, MAE: 0.09527, Word Loss: 19.68, Topo Loss: 7.56, Assm Loss: 364.05, Pred Loss: 82.34, Word: 92.74, Topo: 98.46, Assm: 86.60, PNorm: 190.10, GNorm: 50.00\n",
      "[Train][4000] Alpha: 120.719, Beta: 0.000, Loss: 24483.49, KL: 620915.31, MAE: 0.09233, Word Loss: 17.47, Topo Loss: 2.08, Assm Loss: 287.18, Pred Loss: 258.32, Word: 92.96, Topo: 98.77, Assm: 88.91, PNorm: 191.54, GNorm: 50.00\n",
      "[Train][4100] Alpha: 60.336, Beta: 0.000, Loss: 35371.32, KL: 468977.22, MAE: 0.16088, Word Loss: 41.15, Topo Loss: 16.72, Assm Loss: 632.63, Pred Loss: 821.50, Word: 93.37, Topo: 98.79, Assm: 85.95, PNorm: 192.89, GNorm: 50.00\n",
      "[Train][4200] Alpha: 114.806, Beta: 0.000, Loss: 125837.48, KL: 3420479.75, MAE: 0.29533, Word Loss: 192.18, Topo Loss: 15.91, Assm Loss: 9440.06, Pred Loss: 2016.40, Word: 93.36, Topo: 98.91, Assm: 87.15, PNorm: 194.28, GNorm: 50.00\n",
      "[Train][4300] Alpha: 84.126, Beta: 0.000, Loss: 202314.70, KL: 2939380.53, MAE: 0.27202, Word Loss: 78.62, Topo Loss: 34.61, Assm Loss: 22915.43, Pred Loss: 2203.21, Word: 93.85, Topo: 98.84, Assm: 89.58, PNorm: 195.57, GNorm: 50.00\n",
      "[Train][4400] Alpha: 124.413, Beta: 0.000, Loss: 7179.82, KL: 211735.55, MAE: 0.06898, Word Loss: 11.80, Topo Loss: 3.40, Assm Loss: 393.40, Pred Loss: 102.28, Word: 94.76, Topo: 98.96, Assm: 91.03, PNorm: 196.91, GNorm: 50.00\n",
      "[Train][4500] Alpha: 76.180, Beta: 0.000, Loss: 206032.56, KL: 1837014.47, MAE: 0.30724, Word Loss: 71.91, Topo Loss: 7.28, Assm Loss: 2991.76, Pred Loss: 2479.47, Word: 94.68, Topo: 99.02, Assm: 90.19, PNorm: 198.17, GNorm: 50.00\n",
      "[Train][4600] Alpha: 71.439, Beta: 0.000, Loss: 1961132.83, KL: 105184356.45, MAE: 0.76235, Word Loss: 425.75, Topo Loss: 29.48, Assm Loss: 978.72, Pred Loss: 21629.73, Word: 95.25, Topo: 99.02, Assm: 91.17, PNorm: 199.22, GNorm: 50.00\n",
      "[Train][4700] Alpha: 72.159, Beta: 0.000, Loss: 21121975.82, KL: 824587077.63, MAE: 2.49350, Word Loss: 34.73, Topo Loss: 2.08, Assm Loss: 673726.65, Pred Loss: 356730.43, Word: 95.89, Topo: 99.27, Assm: 90.95, PNorm: 200.37, GNorm: 50.00\n",
      "[Train][4800] Alpha: 94.478, Beta: 0.000, Loss: 10601.51, KL: 177411.75, MAE: 0.09533, Word Loss: 17.20, Topo Loss: 3.63, Assm Loss: 263.94, Pred Loss: 125.23, Word: 95.33, Topo: 99.00, Assm: 89.59, PNorm: 201.61, GNorm: 50.00\n",
      "[Train][4900] Alpha: 47.560, Beta: 0.000, Loss: 44.02, KL: 916.63, MAE: 0.02686, Word Loss: 3.94, Topo Loss: 1.25, Assm Loss: 5.06, Pred Loss: 0.68, Word: 95.99, Topo: 99.31, Assm: 93.06, PNorm: 202.70, GNorm: 50.00\n",
      "[Train][5000] Alpha: 184.287, Beta: 0.000, Loss: 160102.01, KL: 24989174.60, MAE: 0.24886, Word Loss: 166.98, Topo Loss: 4.08, Assm Loss: 137.57, Pred Loss: 2176.58, Word: 95.77, Topo: 98.98, Assm: 93.31, PNorm: 203.79, GNorm: 50.00\n",
      "[Train][5100] Alpha: 70.580, Beta: 0.000, Loss: 17694.74, KL: 797274.81, MAE: 0.08973, Word Loss: 24.96, Topo Loss: 5.24, Assm Loss: 394.16, Pred Loss: 150.09, Word: 96.18, Topo: 99.23, Assm: 92.81, PNorm: 204.96, GNorm: 50.00\n",
      "[Train][5200] Alpha: 74.241, Beta: 0.000, Loss: 4575937.13, KL: 50261952.00, MAE: 0.92479, Word Loss: 89.26, Topo Loss: 1.86, Assm Loss: 68657.15, Pred Loss: 44455.85, Word: 96.14, Topo: 99.18, Assm: 91.72, PNorm: 206.02, GNorm: 50.00\n",
      "[Train][5300] Alpha: 14.404, Beta: 0.000, Loss: 15485.94, KL: 7794474.35, MAE: 0.12570, Word Loss: 82.77, Topo Loss: 14.11, Assm Loss: 1188.86, Pred Loss: 237.57, Word: 95.77, Topo: 99.16, Assm: 91.51, PNorm: 207.12, GNorm: 50.00\n",
      "[Train][5400] Alpha: 95.886, Beta: 0.000, Loss: 5793.14, KL: 10799.48, MAE: 0.04429, Word Loss: 8.75, Topo Loss: 3.12, Assm Loss: 17.65, Pred Loss: 29.06, Word: 96.46, Topo: 99.52, Assm: 94.77, PNorm: 208.16, GNorm: 50.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "runner.train_gen_pred(\n",
    "    loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    load_epoch=0,\n",
    "    lr=conf[\"lr\"],\n",
    "    anneal_rate=conf[\"anneal_rate\"],\n",
    "    clip_norm=conf[\"clip_norm\"],\n",
    "    num_epochs=conf[\"num_epochs\"],\n",
    "    alpha=conf[\"alpha\"],\n",
    "    beta=conf[\"beta\"],\n",
    "    max_beta=conf[\"max_beta\"],\n",
    "    step_beta=conf[\"step_beta\"],\n",
    "    anneal_iter=conf[\"anneal_iter\"],\n",
    "    kl_anneal_iter=conf[\"kl_anneal_iter\"],\n",
    "    print_iter=100,\n",
    "    save_iter=conf[\"save_iter\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model...\")\n",
    "runner.train_gen_pred_supervised(\n",
    "    loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    load_epoch=0,\n",
    "    lr=conf[\"lr\"],\n",
    "    anneal_rate=conf[\"anneal_rate\"],\n",
    "    clip_norm=conf[\"clip_norm\"],\n",
    "    num_epochs=conf[\"num_epochs\"],\n",
    "    alpha=conf[\"alpha\"],\n",
    "    beta=conf[\"beta\"],\n",
    "    max_beta=conf[\"max_beta\"],\n",
    "    step_beta=conf[\"step_beta\"],\n",
    "    anneal_iter=conf[\"anneal_iter\"],\n",
    "    kl_anneal_iter=conf[\"kl_anneal_iter\"],\n",
    "    print_iter=100,\n",
    "    save_iter=conf[\"save_iter\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Copy of google_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
