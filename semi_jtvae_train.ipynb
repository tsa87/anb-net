{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "gradient": {
     "editing": false,
     "id": "18de9aeb-6551-42f6-8c11-a0e30bd207d6",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "JDinHdioUZRH",
    "outputId": "1a824742-d528-46a2-8d89-7697a166c20f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
    "!pip install -q dive-into-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q toolz\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f728113a-ff43-466d-b34d-77c9b2e11478",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "_RKgd8MsYOYh"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from molecule_optimizer.externals.fast_jtnn.datautils import SemiMolTreeFolder, SemiMolTreeFolderTest\n",
    "from molecule_optimizer.runner.semi_jtvae import SemiJTVAEGeneratorPredictor\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "\n",
    "import rdkit\n",
    "\n",
    "lg = rdkit.RDLogger.logger() \n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6e85f4e2-eab6-4eae-b452-7f089e176039",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "2C4erValhPS-"
   },
   "outputs": [],
   "source": [
    "conf = json.load(open(\"training/configs/rand_gen_zinc250k_config_dict.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": true,
     "id": "30eb7f71-c38e-49f6-8d84-715ff3d80e08",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "SuzGX7ClhKaf",
    "outputId": "ab764f6b-4dd7-4ffc-b6cf-bae47d6cedf7"
   },
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"ZINC_310k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = csv['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = smiles[:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(csv['LogP'][:60000]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor(csv['LogP']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'runner.xml' not in os.listdir(\".\"):\n",
    "#     runner = SemiJTVAEGeneratorPredictor(smiles)\n",
    "#     with open('runner.xml', 'wb') as f:\n",
    "#         pickle.dump(runner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:37<00:00,  3.10s/it]\n",
      "100%|██████████| 12/12 [21:10<00:00, 105.90s/it]\n"
     ]
    }
   ],
   "source": [
    "if 'runner_20.xml' not in os.listdir(\".\"):\n",
    "    runner = SemiJTVAEGeneratorPredictor(smiles)\n",
    "    with open('runner_20.xml', 'wb') as f:\n",
    "        pickle.dump(runner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fc02ae3d-696b-4c2e-b557-760e6a1a75a9",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "uTNMpfWD7b7Q"
   },
   "outputs": [],
   "source": [
    "with open('saved/runner_20_LogP_50_1_iter_1000.xml', 'rb') as f:\n",
    "    runner = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "4ccc9136-0e87-470b-90eb-8e0b92da52bc",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "0-1xXVU15z6N",
    "outputId": "c6c328fe-72e4-4401-bce6-8613e7e9319f"
   },
   "outputs": [],
   "source": [
    "runner.get_model(\n",
    "    \"rand_gen\",\n",
    "    {\n",
    "        \"hidden_size\": conf[\"model\"][\"hidden_size\"],\n",
    "        \"latent_size\": conf[\"model\"][\"latent_size\"],\n",
    "        \"depthT\": conf[\"model\"][\"depthT\"],\n",
    "        \"depthG\": conf[\"model\"][\"depthG\"],\n",
    "        \"label_size\": 1,\n",
    "        \"label_mean\": float(torch.mean(labels)),\n",
    "        \"label_var\": float(torch.var(labels)),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c177219a-298a-4994-98b9-de76833e14fe",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "IGnpfkM_KQXi"
   },
   "outputs": [],
   "source": [
    "labels = runner.get_processed_labels(labels)\n",
    "preprocessed = runner.processed_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_TEST = 10000\n",
    "N_TEST = 200\n",
    "VAL_FRAC = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_id=np.random.permutation(len(labels))\n",
    "X_train = preprocessed[perm_id[N_TEST:]]\n",
    "L_train = torch.tensor(labels.numpy()[perm_id[N_TEST:]])\n",
    "\n",
    "X_test = preprocessed[perm_id[:N_TEST]]\n",
    "L_test = torch.tensor(labels.numpy()[perm_id[:N_TEST]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cut = math.floor(len(X_train) * VAL_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Val = X_train[:val_cut]\n",
    "L_Val = L_train[:val_cut]\n",
    "\n",
    "X_train = X_train[val_cut :]\n",
    "L_train = L_train[val_cut :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(L_train, \"L_train.pt\")\n",
    "\n",
    "torch.save(L_test, \"L_test.pt\")\n",
    "\n",
    "torch.save(L_Val, \"L_Val.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "    \n",
    "with open('test.npy', 'wb') as f:\n",
    "    np.save(f, X_test)\n",
    "    \n",
    "with open('validation.npy', 'wb') as f:\n",
    "    np.save(f, X_Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = torch.load(\"L_train.pt\")\n",
    "L_test = torch.load(\"L_test.pt\")\n",
    "L_Val = torch.load(\"L_Val.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.npy', 'rb') as f:\n",
    "    X_train = np.load(f, allow_pickle=True)\n",
    "\n",
    "with open('test.npy', 'rb') as f:\n",
    "    X_test = np.load(f, allow_pickle=True)\n",
    "\n",
    "with open('validation.npy', 'rb') as f:\n",
    "    X_Val = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7cb9e705-09fa-4075-a487-21887ecaeb95",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "TMxgCK1Y20mu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Model #Params: 4732K\n",
      "[Train][1100] Alpha: 0.000, Beta: 0.000, Loss: 42.56, KL: 623.39, MAE: 0.93123, Word Loss: 29.40, Topo Loss: 7.60, Assm Loss: 5.56, Pred Loss: 0.98, Word: 74.12, Topo: 94.58, Assm: 73.51, PNorm: 133.14, GNorm: 48.76\n",
      "[Train][1200] Alpha: 0.000, Beta: 0.000, Loss: 40.44, KL: 656.49, MAE: 0.83633, Word Loss: 27.93, Topo Loss: 6.99, Assm Loss: 5.53, Pred Loss: 0.80, Word: 75.28, Topo: 95.05, Assm: 73.64, PNorm: 136.61, GNorm: 43.44\n",
      "[Train][1300] Alpha: 0.000, Beta: 0.000, Loss: 39.35, KL: 706.59, MAE: 0.83497, Word Loss: 27.10, Topo Loss: 6.86, Assm Loss: 5.39, Pred Loss: 0.80, Word: 76.17, Topo: 95.12, Assm: 74.81, PNorm: 139.67, GNorm: 37.14\n",
      "[Train][1400] Alpha: 0.000, Beta: 0.000, Loss: 37.37, KL: 736.59, MAE: 0.81558, Word Loss: 25.61, Topo Loss: 6.77, Assm Loss: 4.99, Pred Loss: 0.78, Word: 77.17, Topo: 95.29, Assm: 75.78, PNorm: 142.74, GNorm: 44.04\n",
      "[Train][1500] Alpha: 0.000, Beta: 0.000, Loss: 36.24, KL: 759.37, MAE: 0.80959, Word Loss: 24.89, Topo Loss: 6.22, Assm Loss: 5.12, Pred Loss: 0.79, Word: 77.51, Topo: 95.56, Assm: 74.87, PNorm: 145.52, GNorm: 48.29\n",
      "[Train][5100] Alpha: 0.000, Beta: 0.000, Loss: 16.57, KL: 1496.85, MAE: 0.69514, Word Loss: 11.23, Topo Loss: 3.03, Assm Loss: 2.31, Pred Loss: 0.57, Word: 88.27, Topo: 98.00, Assm: 89.57, PNorm: 210.74, GNorm: 50.00\n",
      "[Train][5200] Alpha: 0.000, Beta: 0.000, Loss: 16.10, KL: 1489.08, MAE: 0.70005, Word Loss: 11.02, Topo Loss: 2.83, Assm Loss: 2.24, Pred Loss: 0.55, Word: 88.69, Topo: 98.15, Assm: 90.23, PNorm: 212.10, GNorm: 46.11\n",
      "[Validation][175] Alpha: 0.000, Beta: 0.000, Loss: 8.62, KL: 782.49, MAE: 0.67560, Word Loss: 5.77, Topo Loss: 1.61, Assm Loss: 1.23, Pred Loss: 0.526351, Word: 88.46, Topo: 97.85, Assm: 89.20\n",
      "[Train][6100] Alpha: 0.000, Beta: 0.000, Loss: 12.85, KL: 1605.31, MAE: 0.72073, Word Loss: 8.58, Topo Loss: 2.49, Assm Loss: 1.78, Pred Loss: 0.59, Word: 90.80, Topo: 98.32, Assm: 91.71, PNorm: 223.40, GNorm: 43.87\n",
      "[Train][6200] Alpha: 0.000, Beta: 0.000, Loss: 13.33, KL: 1633.13, MAE: 0.67363, Word Loss: 9.09, Topo Loss: 2.46, Assm Loss: 1.77, Pred Loss: 0.54, Word: 90.04, Topo: 98.37, Assm: 92.32, PNorm: 224.54, GNorm: 50.00\n",
      "[Train][6300] Alpha: 0.000, Beta: 0.000, Loss: 13.38, KL: 1622.02, MAE: 0.66489, Word Loss: 9.03, Topo Loss: 2.58, Assm Loss: 1.77, Pred Loss: 0.52, Word: 90.18, Topo: 98.21, Assm: 92.19, PNorm: 225.65, GNorm: 47.38\n",
      "[Train][6400] Alpha: 0.000, Beta: 0.000, Loss: 13.16, KL: 1649.84, MAE: 0.68269, Word Loss: 8.66, Topo Loss: 2.66, Assm Loss: 1.83, Pred Loss: 0.55, Word: 90.38, Topo: 98.21, Assm: 91.46, PNorm: 226.74, GNorm: 50.00\n",
      "[Train][6500] Alpha: 0.000, Beta: 0.000, Loss: 13.11, KL: 1631.07, MAE: 0.65778, Word Loss: 8.68, Topo Loss: 2.64, Assm Loss: 1.80, Pred Loss: 0.50, Word: 90.41, Topo: 98.22, Assm: 91.46, PNorm: 227.81, GNorm: 43.28\n",
      "[Train][6600] Alpha: 0.000, Beta: 0.000, Loss: 13.02, KL: 1664.86, MAE: 0.69384, Word Loss: 8.90, Topo Loss: 2.38, Assm Loss: 1.74, Pred Loss: 0.56, Word: 90.40, Topo: 98.36, Assm: 92.07, PNorm: 228.89, GNorm: 50.00\n",
      "[Train][6700] Alpha: 0.000, Beta: 0.000, Loss: 12.97, KL: 1648.87, MAE: 0.68210, Word Loss: 8.71, Topo Loss: 2.51, Assm Loss: 1.75, Pred Loss: 0.54, Word: 90.71, Topo: 98.27, Assm: 92.09, PNorm: 230.10, GNorm: 50.00\n",
      "[Train][6800] Alpha: 0.000, Beta: 0.000, Loss: 13.46, KL: 1694.33, MAE: 0.69307, Word Loss: 9.11, Topo Loss: 2.49, Assm Loss: 1.86, Pred Loss: 0.57, Word: 90.26, Topo: 98.31, Assm: 91.92, PNorm: 231.24, GNorm: 40.89\n",
      "[Train][6900] Alpha: 0.000, Beta: 0.000, Loss: 13.16, KL: 1650.04, MAE: 0.68212, Word Loss: 8.83, Topo Loss: 2.52, Assm Loss: 1.82, Pred Loss: 0.55, Word: 90.37, Topo: 98.28, Assm: 92.09, PNorm: 232.40, GNorm: 50.00\n",
      "[Train][7000] Alpha: 0.000, Beta: 0.000, Loss: 13.07, KL: 1677.93, MAE: 0.64490, Word Loss: 8.98, Topo Loss: 2.39, Assm Loss: 1.70, Pred Loss: 0.50, Word: 90.39, Topo: 98.36, Assm: 92.63, PNorm: 233.56, GNorm: 50.00\n",
      "[Train][7100] Alpha: 0.000, Beta: 0.000, Loss: 12.99, KL: 1692.41, MAE: 0.67386, Word Loss: 8.82, Topo Loss: 2.45, Assm Loss: 1.72, Pred Loss: 0.53, Word: 90.59, Topo: 98.31, Assm: 92.06, PNorm: 234.63, GNorm: 44.95\n",
      "[Train][7200] Alpha: 0.000, Beta: 0.000, Loss: 13.05, KL: 1686.83, MAE: 0.69678, Word Loss: 8.90, Topo Loss: 2.35, Assm Loss: 1.80, Pred Loss: 0.55, Word: 90.45, Topo: 98.44, Assm: 92.27, PNorm: 235.76, GNorm: 50.00\n",
      "[Train][7300] Alpha: 0.000, Beta: 0.000, Loss: 13.28, KL: 1695.47, MAE: 0.68355, Word Loss: 9.11, Topo Loss: 2.47, Assm Loss: 1.71, Pred Loss: 0.55, Word: 90.34, Topo: 98.40, Assm: 92.44, PNorm: 236.91, GNorm: 44.78\n",
      "[Train][7400] Alpha: 0.000, Beta: 0.000, Loss: 13.11, KL: 1723.51, MAE: 0.67867, Word Loss: 8.84, Topo Loss: 2.44, Assm Loss: 1.83, Pred Loss: 0.54, Word: 90.56, Topo: 98.34, Assm: 92.09, PNorm: 237.93, GNorm: 50.00\n",
      "[Train][7500] Alpha: 0.000, Beta: 0.000, Loss: 12.34, KL: 1717.72, MAE: 0.69216, Word Loss: 8.17, Topo Loss: 2.40, Assm Loss: 1.77, Pred Loss: 0.54, Word: 90.99, Topo: 98.40, Assm: 92.36, PNorm: 239.01, GNorm: 34.24\n",
      "[Train][7600] Alpha: 0.000, Beta: 0.000, Loss: 13.24, KL: 1708.21, MAE: 0.68064, Word Loss: 8.95, Topo Loss: 2.45, Assm Loss: 1.84, Pred Loss: 0.54, Word: 90.18, Topo: 98.37, Assm: 91.93, PNorm: 240.28, GNorm: 50.00\n",
      "[Validation][175] Alpha: 0.000, Beta: 0.000, Loss: 7.89, KL: 854.89, MAE: 0.63414, Word Loss: 5.42, Topo Loss: 1.42, Assm Loss: 1.05, Pred Loss: 0.464009, Word: 89.13, Topo: 98.15, Assm: 91.15\n",
      "[Train][7700] Alpha: 0.000, Beta: 0.000, Loss: 12.48, KL: 1704.29, MAE: 0.68711, Word Loss: 8.32, Topo Loss: 2.40, Assm Loss: 1.76, Pred Loss: 0.55, Word: 91.11, Topo: 98.40, Assm: 92.60, PNorm: 241.35, GNorm: 37.16\n",
      "[Train][7800] Alpha: 0.000, Beta: 0.000, Loss: 10.03, KL: 1753.26, MAE: 0.64786, Word Loss: 6.76, Topo Loss: 1.91, Assm Loss: 1.36, Pred Loss: 0.49, Word: 92.54, Topo: 98.80, Assm: 93.79, PNorm: 242.30, GNorm: 50.00\n",
      "[Train][7900] Alpha: 0.000, Beta: 0.000, Loss: 10.66, KL: 1750.78, MAE: 0.64224, Word Loss: 7.23, Topo Loss: 1.99, Assm Loss: 1.44, Pred Loss: 0.48, Word: 92.05, Topo: 98.71, Assm: 93.83, PNorm: 243.23, GNorm: 50.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "runner.train_gen_pred(\n",
    "    X_train,\n",
    "    L_train,\n",
    "    X_test,\n",
    "    L_test,\n",
    "    X_Val,\n",
    "    L_Val,\n",
    "    load_epoch= 1000,\n",
    "    lr=conf[\"lr\"],\n",
    "    anneal_rate=conf[\"anneal_rate\"],\n",
    "    clip_norm=conf[\"clip_norm\"],\n",
    "    num_epochs=conf[\"num_epochs\"],\n",
    "    alpha=conf[\"alpha\"],\n",
    "    max_alpha=conf[\"max_alpha\"],\n",
    "    step_alpha=conf[\"step_alpha\"],\n",
    "    beta=conf[\"beta\"],\n",
    "    max_beta=conf[\"max_beta\"],\n",
    "    step_beta=conf[\"step_beta\"],\n",
    "    anneal_iter=conf[\"anneal_iter\"],\n",
    "    alpha_anneal_iter=conf[\"alpha_anneal_iter\"],\n",
    "    kl_anneal_iter=conf[\"kl_anneal_iter\"],\n",
    "    print_iter=100,\n",
    "    save_iter=1000,\n",
    "    batch_size=conf[\"batch_size\"],\n",
    "    num_workers=conf[\"num_workers\"],\n",
    "    label_pct=0.5,\n",
    "    chem_prop = \"LogP\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model...\")\n",
    "runner.train_gen_pred_supervised(\n",
    "    loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    load_epoch=0,\n",
    "    lr=conf[\"lr\"],\n",
    "    anneal_rate=conf[\"anneal_rate\"],\n",
    "    clip_norm=conf[\"clip_norm\"],\n",
    "    num_epochs=conf[\"num_epochs\"],\n",
    "    alpha=conf[\"alpha\"],\n",
    "    max_alpha=conf[\"max_alpha\"],\n",
    "    step_alpha=conf[\"step_alpha\"],\n",
    "    beta=conf[\"beta\"],\n",
    "    max_beta=conf[\"max_beta\"],\n",
    "    step_beta=conf[\"step_beta\"],\n",
    "    anneal_iter=conf[\"anneal_iter\"],\n",
    "    alpha_anneal_iter=conf[\"alpha_anneal_iter\"],\n",
    "    kl_anneal_iter=conf[\"kl_anneal_iter\"],\n",
    "    print_iter=100,\n",
    "    save_iter=conf[\"save_iter\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Copy of google_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
