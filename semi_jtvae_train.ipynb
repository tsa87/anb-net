{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr:0.001\n",
    "# anneal_rate:0.9\n",
    "# batch_size:32\n",
    "# clip_norm:50\n",
    "# num_epochs:5\n",
    "# alpha:250\n",
    "# beta:0\n",
    "# max_beta:1\n",
    "# step_beta:0.002\n",
    "# anneal_iter:40000\n",
    "# kl_anneal_iter:2000\n",
    "# print_iter:100\n",
    "# save_iter:5000\n",
    "# num_workers:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "gradient": {
     "editing": false,
     "id": "18de9aeb-6551-42f6-8c11-a0e30bd207d6",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "JDinHdioUZRH",
    "outputId": "1a824742-d528-46a2-8d89-7697a166c20f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
    "!pip install -q dive-into-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q toolz\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f728113a-ff43-466d-b34d-77c9b2e11478",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "_RKgd8MsYOYh"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from molecule_optimizer.externals.fast_jtnn.datautils import SemiMolTreeFolder, SemiMolTreeFolderTest\n",
    "from molecule_optimizer.runner.semi_jtvae import SemiJTVAEGeneratorPredictor\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "\n",
    "import rdkit\n",
    "\n",
    "lg = rdkit.RDLogger.logger() \n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6e85f4e2-eab6-4eae-b452-7f089e176039",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "2C4erValhPS-"
   },
   "outputs": [],
   "source": [
    "conf = json.load(open(\"training/configs/rand_gen_zinc250k_config_dict.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": true,
     "id": "30eb7f71-c38e-49f6-8d84-715ff3d80e08",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "SuzGX7ClhKaf",
    "outputId": "ab764f6b-4dd7-4ffc-b6cf-bae47d6cedf7"
   },
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"ZINC_310k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = csv['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'runner.xml' not in os.listdir(\".\"):\n",
    "    runner = SemiJTVAEGeneratorPredictor(smiles)\n",
    "    with open('runner.xml', 'wb') as f:\n",
    "        pickle.dump(runner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fc02ae3d-696b-4c2e-b557-760e6a1a75a9",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "uTNMpfWD7b7Q"
   },
   "outputs": [],
   "source": [
    "with open('runner.xml', 'rb') as f:\n",
    "    runner = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(csv['QED']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "4ccc9136-0e87-470b-90eb-8e0b92da52bc",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "0-1xXVU15z6N",
    "outputId": "c6c328fe-72e4-4401-bce6-8613e7e9319f"
   },
   "outputs": [],
   "source": [
    "runner.get_model(\n",
    "    \"rand_gen\",\n",
    "    {\n",
    "        \"hidden_size\": conf[\"model\"][\"hidden_size\"],\n",
    "        \"latent_size\": conf[\"model\"][\"latent_size\"],\n",
    "        \"depthT\": conf[\"model\"][\"depthT\"],\n",
    "        \"depthG\": conf[\"model\"][\"depthG\"],\n",
    "        \"label_size\": 1,\n",
    "        \"label_mean\": float(torch.mean(labels)),\n",
    "        \"label_var\": float(torch.var(labels)),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c177219a-298a-4994-98b9-de76833e14fe",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "IGnpfkM_KQXi"
   },
   "outputs": [],
   "source": [
    "labels = runner.get_processed_labels(labels)\n",
    "preprocessed = runner.processed_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST = 10000\n",
    "VAL_FRAC = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_id=np.random.permutation(len(labels))\n",
    "X_train = preprocessed[perm_id[N_TEST:]]\n",
    "L_train = torch.tensor(labels.numpy()[perm_id[N_TEST:]])\n",
    "\n",
    "\n",
    "X_test = preprocessed[perm_id[:N_TEST]]\n",
    "L_test = torch.tensor(labels.numpy()[perm_id[:N_TEST]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cut = math.floor(len(X_train) * VAL_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Val = X_train[:val_cut]\n",
    "L_Val = L_train[:val_cut]\n",
    "\n",
    "X_train = X_train[val_cut :]\n",
    "L_train = L_train[val_cut :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = SemiMolTreeFolder(\n",
    "    X_train,\n",
    "    L_train,\n",
    "    runner.vocab,\n",
    "    conf[\"batch_size\"],\n",
    "    label_pct=0.05,\n",
    "    num_workers=conf[\"num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "25d5a0be-b1f8-454e-bc3a-82d8489ac3ca",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "k19uZMZN9H05"
   },
   "outputs": [],
   "source": [
    "test_loader = SemiMolTreeFolderTest(\n",
    "    X_test,\n",
    "    L_test,\n",
    "    runner.vocab,\n",
    "    conf[\"batch_size\"],\n",
    "    num_workers=conf[\"num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = SemiMolTreeFolderTest(\n",
    "    X_Val,\n",
    "    L_Val,\n",
    "    runner.vocab,\n",
    "    conf[\"batch_size\"],\n",
    "    num_workers=conf[\"num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7cb9e705-09fa-4075-a487-21887ecaeb95",
     "kernelId": "dcb13b96-53c0-4a94-b7ff-08f48ec3f7ee"
    },
    "id": "TMxgCK1Y20mu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Model #Params: 5207K\n",
      "[Train][100] Alpha: 250.000, Beta: 0.000, Loss: 336.13, KL: 65.95, MAE: 0.11478, Word Loss: 94.62, Topo Loss: 24.33, Assm Loss: 8.67, Pred Loss: 0.83, Word: 27.99, Topo: 80.27, Assm: 56.75, PNorm: 104.78, GNorm: 50.00\n",
      "[Train][200] Alpha: 250.000, Beta: 0.000, Loss: 243.04, KL: 88.82, MAE: 0.10004, Word Loss: 60.39, Topo Loss: 16.34, Assm Loss: 8.43, Pred Loss: 0.63, Word: 45.63, Topo: 88.16, Assm: 57.98, PNorm: 109.01, GNorm: 50.00\n",
      "[Train][300] Alpha: 250.000, Beta: 0.000, Loss: 206.80, KL: 134.84, MAE: 0.09060, Word Loss: 53.74, Topo Loss: 12.51, Assm Loss: 8.52, Pred Loss: 0.53, Word: 51.82, Topo: 91.31, Assm: 58.39, PNorm: 112.61, GNorm: 50.00\n",
      "[Train][400] Alpha: 250.000, Beta: 0.000, Loss: 193.86, KL: 145.27, MAE: 0.08911, Word Loss: 49.17, Topo Loss: 11.03, Assm Loss: 7.96, Pred Loss: 0.50, Word: 55.44, Topo: 92.25, Assm: 61.04, PNorm: 115.28, GNorm: 50.00\n",
      "[Train][500] Alpha: 250.000, Beta: 0.000, Loss: 192.00, KL: 158.57, MAE: 0.08794, Word Loss: 48.49, Topo Loss: 11.85, Assm Loss: 7.95, Pred Loss: 0.49, Word: 56.88, Topo: 91.57, Assm: 59.74, PNorm: 118.45, GNorm: 50.00\n",
      "[Train][600] Alpha: 250.000, Beta: 0.000, Loss: 174.55, KL: 175.35, MAE: 0.08142, Word Loss: 46.06, Topo Loss: 11.12, Assm Loss: 8.14, Pred Loss: 0.44, Word: 59.11, Topo: 92.37, Assm: 59.67, PNorm: 121.55, GNorm: 50.00\n",
      "[Train][700] Alpha: 250.000, Beta: 0.000, Loss: 164.26, KL: 206.26, MAE: 0.08005, Word Loss: 44.55, Topo Loss: 9.50, Assm Loss: 7.66, Pred Loss: 0.41, Word: 59.99, Topo: 93.20, Assm: 62.28, PNorm: 124.50, GNorm: 50.00\n",
      "[Train][800] Alpha: 250.000, Beta: 0.000, Loss: 149.06, KL: 235.13, MAE: 0.07281, Word Loss: 43.62, Topo Loss: 9.63, Assm Loss: 7.93, Pred Loss: 0.35, Word: 60.86, Topo: 93.20, Assm: 61.80, PNorm: 127.68, GNorm: 50.00\n",
      "[Train][900] Alpha: 250.000, Beta: 0.000, Loss: 150.33, KL: 241.27, MAE: 0.07562, Word Loss: 42.34, Topo Loss: 9.39, Assm Loss: 7.12, Pred Loss: 0.37, Word: 61.11, Topo: 93.24, Assm: 63.22, PNorm: 129.76, GNorm: 50.00\n",
      "[Train][1000] Alpha: 250.000, Beta: 0.000, Loss: 153.46, KL: 249.78, MAE: 0.07619, Word Loss: 42.18, Topo Loss: 9.39, Assm Loss: 7.45, Pred Loss: 0.38, Word: 61.44, Topo: 93.23, Assm: 63.49, PNorm: 132.20, GNorm: 50.00\n",
      "[Train][1100] Alpha: 250.000, Beta: 0.000, Loss: 147.81, KL: 238.99, MAE: 0.07355, Word Loss: 41.75, Topo Loss: 9.17, Assm Loss: 7.54, Pred Loss: 0.36, Word: 62.52, Topo: 93.44, Assm: 63.57, PNorm: 134.63, GNorm: 50.00\n",
      "[Train][1200] Alpha: 250.000, Beta: 0.000, Loss: 141.03, KL: 270.77, MAE: 0.07225, Word Loss: 40.41, Topo Loss: 8.04, Assm Loss: 7.42, Pred Loss: 0.34, Word: 62.85, Topo: 94.16, Assm: 64.00, PNorm: 136.93, GNorm: 50.00\n",
      "[Train][1300] Alpha: 250.000, Beta: 0.000, Loss: 144.06, KL: 272.86, MAE: 0.07357, Word Loss: 39.90, Topo Loss: 8.12, Assm Loss: 7.16, Pred Loss: 0.36, Word: 63.47, Topo: 94.22, Assm: 64.80, PNorm: 138.95, GNorm: 50.00\n",
      "[Train][1400] Alpha: 250.000, Beta: 0.000, Loss: 140.72, KL: 251.43, MAE: 0.07199, Word Loss: 39.54, Topo Loss: 8.56, Assm Loss: 7.48, Pred Loss: 0.34, Word: 63.98, Topo: 94.08, Assm: 62.30, PNorm: 141.63, GNorm: 50.00\n",
      "[Train][1500] Alpha: 250.000, Beta: 0.000, Loss: 125.81, KL: 301.02, MAE: 0.06607, Word Loss: 38.38, Topo Loss: 7.50, Assm Loss: 7.39, Pred Loss: 0.29, Word: 65.08, Topo: 94.78, Assm: 64.68, PNorm: 143.73, GNorm: 50.00\n",
      "[Train][1600] Alpha: 250.000, Beta: 0.000, Loss: 122.71, KL: 305.78, MAE: 0.06595, Word Loss: 37.99, Topo Loss: 7.42, Assm Loss: 7.14, Pred Loss: 0.28, Word: 65.06, Topo: 94.69, Assm: 65.00, PNorm: 146.08, GNorm: 50.00\n",
      "[Train][1700] Alpha: 250.000, Beta: 0.000, Loss: 115.49, KL: 313.16, MAE: 0.06194, Word Loss: 37.20, Topo Loss: 8.05, Assm Loss: 6.93, Pred Loss: 0.25, Word: 64.95, Topo: 94.26, Assm: 66.16, PNorm: 148.46, GNorm: 50.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "runner.train_gen_pred(\n",
    "    loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    load_epoch=0,\n",
    "    lr=conf[\"lr\"],\n",
    "    anneal_rate=conf[\"anneal_rate\"],\n",
    "    clip_norm=conf[\"clip_norm\"],\n",
    "    num_epochs=conf[\"num_epochs\"],\n",
    "    alpha=conf[\"alpha\"],\n",
    "    beta=conf[\"beta\"],\n",
    "    max_beta=conf[\"max_beta\"],\n",
    "    step_beta=conf[\"step_beta\"],\n",
    "    anneal_iter=conf[\"anneal_iter\"],\n",
    "    kl_anneal_iter=conf[\"kl_anneal_iter\"],\n",
    "    print_iter=100,\n",
    "    save_iter=conf[\"save_iter\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Model #Params: 5207K\n",
      "[Train][100] Alpha: 1.000, Beta: 0.000, Loss: 60.34, KL: 166.62, MAE: 0.11884, Word Loss: 45.12, Topo Loss: 9.87, Assm Loss: 4.47, Pred Loss: 0.89, Word: 28.59, Topo: 84.86, Assm: 54.80, PNorm: 103.63, GNorm: 35.51\n",
      "[Train][200] Alpha: 1.000, Beta: 0.000, Loss: 38.86, KL: 164.02, MAE: 0.10257, Word Loss: 28.00, Topo Loss: 6.06, Assm Loss: 4.13, Pred Loss: 0.67, Word: 50.60, Topo: 91.49, Assm: 59.06, PNorm: 108.04, GNorm: 46.30\n",
      "[Train][300] Alpha: 1.000, Beta: 0.000, Loss: 33.42, KL: 184.05, MAE: 0.09147, Word Loss: 23.80, Topo Loss: 5.25, Assm Loss: 3.84, Pred Loss: 0.53, Word: 59.80, Topo: 92.62, Assm: 60.15, PNorm: 111.32, GNorm: 35.47\n",
      "[Train][400] Alpha: 1.000, Beta: 0.000, Loss: 30.39, KL: 195.26, MAE: 0.08689, Word Loss: 21.25, Topo Loss: 4.83, Assm Loss: 3.84, Pred Loss: 0.48, Word: 63.47, Topo: 93.24, Assm: 61.96, PNorm: 114.29, GNorm: 25.53\n",
      "[Train][500] Alpha: 1.000, Beta: 0.000, Loss: 28.59, KL: 218.78, MAE: 0.08508, Word Loss: 19.85, Topo Loss: 4.55, Assm Loss: 3.74, Pred Loss: 0.46, Word: 65.73, Topo: 93.51, Assm: 62.95, PNorm: 116.86, GNorm: 37.04\n",
      "[Train][600] Alpha: 1.000, Beta: 0.000, Loss: 27.26, KL: 237.86, MAE: 0.07666, Word Loss: 18.77, Topo Loss: 4.44, Assm Loss: 3.66, Pred Loss: 0.38, Word: 67.25, Topo: 93.63, Assm: 64.01, PNorm: 119.42, GNorm: 22.45\n",
      "[Train][700] Alpha: 1.000, Beta: 0.000, Loss: 25.84, KL: 255.38, MAE: 0.08110, Word Loss: 17.61, Topo Loss: 4.28, Assm Loss: 3.53, Pred Loss: 0.42, Word: 69.08, Topo: 93.98, Assm: 65.57, PNorm: 122.05, GNorm: 32.02\n",
      "[Train][800] Alpha: 1.000, Beta: 0.000, Loss: 25.26, KL: 260.68, MAE: 0.07885, Word Loss: 17.16, Topo Loss: 4.19, Assm Loss: 3.51, Pred Loss: 0.40, Word: 69.89, Topo: 94.10, Assm: 64.42, PNorm: 124.61, GNorm: 26.60\n",
      "[Train][900] Alpha: 1.000, Beta: 0.000, Loss: 23.63, KL: 289.36, MAE: 0.07532, Word Loss: 16.28, Topo Loss: 3.74, Assm Loss: 3.25, Pred Loss: 0.36, Word: 71.55, Topo: 94.65, Assm: 67.16, PNorm: 126.85, GNorm: 33.05\n",
      "[Train][1000] Alpha: 1.000, Beta: 0.000, Loss: 22.91, KL: 300.94, MAE: 0.07690, Word Loss: 15.69, Topo Loss: 3.73, Assm Loss: 3.11, Pred Loss: 0.38, Word: 71.93, Topo: 94.65, Assm: 70.66, PNorm: 129.16, GNorm: 35.46\n",
      "[Train][1100] Alpha: 1.000, Beta: 0.000, Loss: 22.05, KL: 308.20, MAE: 0.07549, Word Loss: 15.20, Topo Loss: 3.70, Assm Loss: 2.78, Pred Loss: 0.37, Word: 72.81, Topo: 94.71, Assm: 72.46, PNorm: 131.39, GNorm: 22.67\n",
      "[Train][1200] Alpha: 1.000, Beta: 0.000, Loss: 20.94, KL: 329.53, MAE: 0.07782, Word Loss: 14.38, Topo Loss: 3.43, Assm Loss: 2.74, Pred Loss: 0.39, Word: 74.51, Topo: 95.20, Assm: 73.09, PNorm: 133.43, GNorm: 36.28\n",
      "[Train][1300] Alpha: 1.000, Beta: 0.000, Loss: 20.11, KL: 348.85, MAE: 0.07147, Word Loss: 13.70, Topo Loss: 3.36, Assm Loss: 2.72, Pred Loss: 0.33, Word: 75.01, Topo: 95.29, Assm: 73.37, PNorm: 135.60, GNorm: 29.08\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "runner.train_gen_pred_supervised(\n",
    "    loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    load_epoch=0,\n",
    "    lr=conf[\"lr\"],\n",
    "    anneal_rate=conf[\"anneal_rate\"],\n",
    "    clip_norm=conf[\"clip_norm\"],\n",
    "    num_epochs=conf[\"num_epochs\"],\n",
    "    alpha=1,\n",
    "    beta=conf[\"beta\"],\n",
    "    max_beta=conf[\"max_beta\"],\n",
    "    step_beta=conf[\"step_beta\"],\n",
    "    anneal_iter=conf[\"anneal_iter\"],\n",
    "    kl_anneal_iter=conf[\"kl_anneal_iter\"],\n",
    "    print_iter=100,\n",
    "    save_iter=conf[\"save_iter\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Copy of google_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
